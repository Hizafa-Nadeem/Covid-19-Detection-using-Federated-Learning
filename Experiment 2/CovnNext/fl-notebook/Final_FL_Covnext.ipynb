{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ex6Qy-IuzYBJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\", font_scale=1.4)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import dill\n",
    "import base64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "path = 'XRayDataSet/'\n",
    "#path = '/content/drive/MyDrive/Colab Notebooks/XRayDataSet/'\n",
    "image_dataset = torchvision.datasets.ImageFolder(root=path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504\n",
      "126\n",
      "Covid-19 Class:  1\n",
      "Not-Covid-19 Class:  0\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = train_test_split(image_dataset, test_size=0.2)\n",
    "\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "\n",
    "class_num_covid = image_dataset.class_to_idx['Covid-19']\n",
    "class_num_not_covid = image_dataset.class_to_idx['ANo_findings']\n",
    "print('Covid-19 Class: ', class_num_covid)\n",
    "print('Not-Covid-19 Class: ', class_num_not_covid)\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.Tensor([0.5, 0.5, 0.5]), torch.Tensor([0.5, 0.5, 0.5]))\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.Tensor([0.5, 0.5, 0.5]), torch.Tensor([0.5, 0.5, 0.5]))\n",
    "])\n",
    "\n",
    "# client_dataset = []\n",
    "# for i in range(len(train_dataset)):\n",
    "#     # client_dataset.append((train_transforms(train_dataset[i][0]), torch.Tensor([class_num_covid]) if train_dataset[i][1] == class_num_covid else torch.Tensor([class_num_not_covid])))\n",
    "#     client_dataset.append((train_transforms(train_dataset[i][0]), torch.Tensor([1,0]) if train_dataset[i][1] == class_num_covid else torch.Tensor([0,1])))\n",
    "#\n",
    "# client_loader = torch.utils.data.DataLoader(dataset=client_dataset, batch_size=32)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_global_weights_from_server():\n",
    "  res = requests.get(\"http://127.0.0.1:7000/get_global_model/\")\n",
    "  jsn = json.loads(res.text)\n",
    "  return jsn['global_model']\n",
    "\n",
    "\n",
    "def send_local_gradients_to_server(local_grads):\n",
    "  s_obj = dill.dumps({\n",
    "    'local_grads': local_grads\n",
    "  })\n",
    "\n",
    "  encoded = base64.b64encode(s_obj)\n",
    "\n",
    "  data_post = {\"local_grads\": encoded.decode('ascii')}\n",
    "  data_post = json.dumps(data_post)\n",
    "\n",
    "  res = requests.post(\"http://127.0.0.1:7000/collect_model_updates/\", data=data_post)\n",
    "  if res.status_code == 200:\n",
    "    return True\n",
    "  return False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def c_mat(y_true, y_pred):\n",
    "    _t = [int(1 if i[0] < i[1] else 0) for i in y_true]\n",
    "    # print('y_pred: ' + str(y_pred))\n",
    "    # _p = [int(1 if i[0] > 0 else 0) for i in y_pred]\n",
    "    _p = [int(1 if i[0] < i[1] else 0) for i in y_pred]\n",
    "    # print('target: ' + str(_t))\n",
    "    # print('predicted: ' + str(_p))\n",
    "    tn, fp, fn, tp = confusion_matrix(_t, _p, labels=[0, 1]).ravel()\n",
    "    # print('tn: ' + str(tn), ' fp: ' + str(fp), ' fn: ' + str(fn), ' tp: ' + str(tp))\n",
    "    # print('fp: ' + str(fp))\n",
    "    # print('fn: ' + str(fn))\n",
    "    # print('tp: ' + str(tp))\n",
    "    return tn, fp, fn, tp\n",
    "\n",
    "class FL_Client():\n",
    "    def __init__(self, input , target):\n",
    "        self.input = input\n",
    "        self.target = target\n",
    "        self.ae = torch.load(\"model1.pt\")\n",
    "        # self.criterion = nn.MSELoss()\n",
    "        # self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.ae.parameters(), lr = 2e-5)\n",
    "\n",
    "    def set_input_and_target(self, input , target):\n",
    "        self.input = input\n",
    "        self.target = target\n",
    "\n",
    "    def train_model(self):\n",
    "      self.optimizer.zero_grad()\n",
    "      #print(self.input.shape)\n",
    "      output = self.ae(self.input)\n",
    "      self.target.requires_grad = False\n",
    "      #print(\"Output: \", output)\n",
    "      tn, fp, fn, tp = c_mat(self.target, output)\n",
    "      loss = self.criterion(output, self.target)\n",
    "      loss.backward()\n",
    "      return loss.item(), tn, fp, fn, tp\n",
    "\n",
    "    def get_gradients(self):\n",
    "      with torch.no_grad():\n",
    "        gradients_arr = []\n",
    "        for param in self.ae.parameters():\n",
    "\n",
    "          #if param.grad is not None:\n",
    "          if param.requires_grad==True:\n",
    "            grad = param.grad.numpy()\n",
    "            gradients_arr.append(grad)\n",
    "\n",
    "          #gradients_arr.append(grad)\n",
    "          #gradients_arr.append(param.grad.numpy())\n",
    "\n",
    "        return gradients_arr\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "      with torch.no_grad():\n",
    "        i = 0\n",
    "        for name, param in self.ae.named_parameters():\n",
    "          param.data = torch.Tensor(weights[i])\n",
    "          i += 1\n",
    "    def train_test_model_and_get_loss(self, input, target):\n",
    "      with torch.no_grad():\n",
    "        output = self.ae(input)\n",
    "        tn, fp, fn, tp = c_mat(target, output)\n",
    "        loss = self.criterion(output, target)\n",
    "        return loss.item(), tn, fp, fn, tp\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_dataset1, test_dataset1 = train_test_split(image_dataset, test_size=0.2, random_state=40)\n",
    "client_dataset1 = []\n",
    "for i in range(len(train_dataset1)):\n",
    "    # client_dataset.append((train_transforms(train_dataset[i][0]), torch.Tensor([class_num_covid]) if train_dataset[i][1] == class_num_covid else torch.Tensor([class_num_not_covid])))\n",
    "    client_dataset1.append((train_transforms(train_dataset1[i][0]), torch.Tensor([1,0]) if train_dataset1[i][1] == class_num_covid else torch.Tensor([0,1])))\n",
    "\n",
    "client_loader1 = torch.utils.data.DataLoader(dataset=client_dataset1, batch_size=128)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "clients_arr = []\n",
    "for batch_idx, (train_features, train_labels) in enumerate(client_loader1):\n",
    "    clients_arr.append(FL_Client(train_features, train_labels))\n",
    "length=len(clients_arr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FL_ITER:  10\n",
      "NUM_CLIENTS_PER_FL_ITER:  50\n",
      "Batch Idx Size:  4\n",
      "--------Epoch  1 Client  1 . Local Loss:  0.6856427788734436 . L-AC:  0.5703125 . L-P:  0.835820895522388 . L-R:  0.56 . L-F1:  0.6706586826347306\n",
      "--------Epoch  1 Client  2 . Local Loss:  0.664919376373291 . L-AC:  1.171875 . L-P:  1.692963752665245 . L-R:  1.1540594059405942 . L-F1:  2.0431664803138756\n",
      "--------Epoch  1 Client  3 . Local Loss:  0.6836732625961304 . L-AC:  1.7265625 . L-P:  2.589515476803176 . L-R:  1.658913774872633 . L-F1:  4.065458786591625\n",
      "--------Epoch  1 Client  4 . Local Loss:  0.684779167175293 . L-AC:  2.2682291666666665 . L-P:  3.4076972949849944 . L-R:  2.158913774872633 . L-F1:  6.708691639907341\n",
      "Epoch  1 . Loss:  0.6797536462545395 . Accuracy:  0.5670572916666666 . Precision:  0.8519243237462486 . Recall:  0.5397284437181582 . F1-Score:  0.660808213328929\n",
      "--------Epoch  2 Client  1 . Local Loss:  0.5043511390686035 . L-AC:  0.78125 . L-P:  0.78125 . L-R:  1.0 . L-F1:  0.8771929824561403\n",
      "--------Epoch  2 Client  2 . Local Loss:  0.48606058955192566 . L-AC:  1.5703125 . L-P:  1.5703125 . L-R:  2.0 . L-F1:  2.6364927636377598\n",
      "--------Epoch  2 Client  3 . Local Loss:  0.4592556357383728 . L-AC:  2.375 . L-P:  2.375 . L-R:  3.0 . L-F1:  5.287655554335434\n",
      "--------Epoch  2 Client  4 . Local Loss:  0.5459088087081909 . L-AC:  3.125 . L-P:  3.125 . L-R:  4.0 . L-F1:  8.796427484159995\n",
      "Epoch  2 . Loss:  0.4988940432667732 . Accuracy:  0.78125 . Precision:  0.78125 . Recall:  1.0 . F1-Score:  0.8771929824561403\n",
      "--------Epoch  3 Client  1 . Local Loss:  0.45366084575653076 . L-AC:  0.8125 . L-P:  0.8114754098360656 . L-R:  0.99 . L-F1:  0.891891891891892\n",
      "--------Epoch  3 Client  2 . Local Loss:  0.42560121417045593 . L-AC:  1.6796875 . L-P:  1.6674076132258961 . L-R:  1.99 . L-F1:  2.7063689757807596\n",
      "--------Epoch  3 Client  3 . Local Loss:  0.4210481643676758 . L-AC:  2.546875 . L-P:  2.5257409465592295 . L-R:  2.99 . L-F1:  5.444701143074832\n",
      "--------Epoch  3 Client  4 . Local Loss:  0.45202723145484924 . L-AC:  3.346875 . L-P:  3.3152146307697556 . L-R:  3.99 . L-F1:  9.066143371768806\n",
      "Epoch  3 . Loss:  0.43808436393737793 . Accuracy:  0.83671875 . Precision:  0.8288036576924389 . Recall:  0.9975 . F1-Score:  0.9053605571734936\n",
      "--------Epoch  4 Client  1 . Local Loss:  0.43545979261398315 . L-AC:  0.78125 . L-P:  0.78125 . L-R:  1.0 . L-F1:  0.8771929824561403\n",
      "--------Epoch  4 Client  2 . Local Loss:  0.4069506824016571 . L-AC:  1.5703125 . L-P:  1.5703125 . L-R:  2.0 . L-F1:  2.6364927636377598\n",
      "--------Epoch  4 Client  3 . Local Loss:  0.3796785771846771 . L-AC:  2.375 . L-P:  2.375 . L-R:  3.0 . L-F1:  5.287655554335434\n",
      "--------Epoch  4 Client  4 . Local Loss:  0.48041316866874695 . L-AC:  3.125 . L-P:  3.125 . L-R:  4.0 . L-F1:  8.796427484159995\n",
      "Epoch  4 . Loss:  0.4256255552172661 . Accuracy:  0.78125 . Precision:  0.78125 . Recall:  1.0 . F1-Score:  0.8771929824561403\n",
      "--------Epoch  5 Client  1 . Local Loss:  0.3800097107887268 . L-AC:  0.8828125 . L-P:  0.8828828828828829 . L-R:  0.98 . L-F1:  0.9289099526066351\n",
      "--------Epoch  5 Client  2 . Local Loss:  0.3596022129058838 . L-AC:  1.8046875 . L-P:  1.7927927927927927 . L-R:  1.98 . L-F1:  2.810661707704777\n",
      "--------Epoch  5 Client  3 . Local Loss:  0.3489851653575897 . L-AC:  2.765625 . L-P:  2.7464964964964964 . L-R:  2.98 . L-F1:  5.669149288921991\n",
      "--------Epoch  5 Client  4 . Local Loss:  0.38195928931236267 . L-AC:  3.6822916666666665 . L-P:  3.6464964964964963 . L-R:  3.98 . L-F1:  9.475105552777393\n",
      "Epoch  5 . Loss:  0.36763909459114075 . Accuracy:  0.9205729166666666 . Precision:  0.9116241241241241 . Recall:  0.995 . F1-Score:  0.9514890659638502\n",
      "--------Epoch  6 Client  1 . Local Loss:  0.3888474106788635 . L-AC:  0.78125 . L-P:  0.78125 . L-R:  1.0 . L-F1:  0.8771929824561403\n",
      "--------Epoch  6 Client  2 . Local Loss:  0.359304279088974 . L-AC:  1.5859375 . L-P:  1.5828373015873016 . L-R:  2.0 . L-F1:  2.644325752773183\n",
      "--------Epoch  6 Client  3 . Local Loss:  0.31187328696250916 . L-AC:  2.40625 . L-P:  2.400297619047619 . L-R:  3.0 . L-F1:  5.311176124776489\n",
      "--------Epoch  6 Client  4 . Local Loss:  0.4081379175186157 . L-AC:  3.15625 . L-P:  3.150297619047619 . L-R:  4.0 . L-F1:  8.835837935390433\n",
      "Epoch  6 . Loss:  0.3670407235622406 . Accuracy:  0.7890625 . Precision:  0.7875744047619048 . Recall:  1.0 . F1-Score:  0.8811654526534859\n",
      "--------Epoch  7 Client  1 . Local Loss:  0.3405914902687073 . L-AC:  0.9140625 . L-P:  0.908256880733945 . L-R:  0.99 . L-F1:  0.9473684210526315\n",
      "--------Epoch  7 Client  2 . Local Loss:  0.31255602836608887 . L-AC:  1.859375 . L-P:  1.8434420659191302 . L-R:  1.99 . L-F1:  2.861287895038212\n",
      "--------Epoch  7 Client  3 . Local Loss:  0.30625420808792114 . L-AC:  2.828125 . L-P:  2.8060588883490367 . L-R:  2.99 . L-F1:  5.756398603119192\n",
      "--------Epoch  7 Client  4 . Local Loss:  0.34048280119895935 . L-AC:  3.7614583333333336 . L-P:  3.73314222168237 . L-R:  3.978888888888889 . L-F1:  9.608498755083877\n",
      "Epoch  7 . Loss:  0.32497113198041916 . Accuracy:  0.9403645833333334 . Precision:  0.9332855554205925 . Recall:  0.9947222222222223 . F1-Score:  0.9630250379911713\n",
      "--------Epoch  8 Client  1 . Local Loss:  0.34043312072753906 . L-AC:  0.78125 . L-P:  0.78125 . L-R:  1.0 . L-F1:  0.8771929824561403\n",
      "--------Epoch  8 Client  2 . Local Loss:  0.31883561611175537 . L-AC:  1.5859375 . L-P:  1.5828373015873016 . L-R:  2.0 . L-F1:  2.644325752773183\n",
      "--------Epoch  8 Client  3 . Local Loss:  0.27518975734710693 . L-AC:  2.4296875 . L-P:  2.4202356755710417 . L-R:  3.0 . L-F1:  5.323436943246717\n",
      "--------Epoch  8 Client  4 . Local Loss:  0.37843430042266846 . L-AC:  3.2213541666666665 . L-P:  3.2028443712232155 . L-R:  4.0 . L-F1:  8.880747590156385\n",
      "Epoch  8 . Loss:  0.32822319865226746 . Accuracy:  0.8053385416666666 . Precision:  0.8007110928058039 . Recall:  1.0 . F1-Score:  0.8893276617274172\n",
      "--------Epoch  9 Client  1 . Local Loss:  0.29646897315979004 . L-AC:  0.921875 . L-P:  0.9166666666666666 . L-R:  0.99 . L-F1:  0.9519230769230769\n",
      "--------Epoch  9 Client  2 . Local Loss:  0.27957883477211 . L-AC:  1.8828125 . L-P:  1.869496855345912 . L-R:  1.99 . L-F1:  2.879790299815232\n",
      "--------Epoch  9 Client  3 . Local Loss:  0.2692689597606659 . L-AC:  2.8359375 . L-P:  2.822767883383295 . L-R:  2.980291262135922 . L-F1:  5.7791818954983185\n",
      "--------Epoch  9 Client  4 . Local Loss:  0.2970215380191803 . L-AC:  3.7942708333333335 . L-P:  3.7701363044359266 . L-R:  3.980291262135922 . L-F1:  9.651546474281231\n",
      "Epoch  9 . Loss:  0.28558457642793655 . Accuracy:  0.9485677083333334 . Precision:  0.9425340761089817 . Recall:  0.9950728155339805 . F1-Score:  0.9680911446957281\n",
      "--------Epoch  10 Client  1 . Local Loss:  0.3158140182495117 . L-AC:  0.8203125 . L-P:  0.8130081300813008 . L-R:  1.0 . L-F1:  0.8968609865470852\n",
      "--------Epoch  10 Client  2 . Local Loss:  0.29501307010650635 . L-AC:  1.6640625 . L-P:  1.6477188738829538 . L-R:  2.0 . L-F1:  2.703709519399044\n",
      "--------Epoch  10 Client  3 . Local Loss:  0.2452056109905243 . L-AC:  2.515625 . L-P:  2.491981168964921 . L-R:  3.0 . L-F1:  5.426203743939061\n",
      "--------Epoch  10 Client  4 . Local Loss:  0.3281993865966797 . L-AC:  3.3322916666666664 . L-P:  3.29555259753635 . L-R:  4.0 . L-F1:  9.039969860736553\n",
      "Epoch  10 . Loss:  0.2960580214858055 . Accuracy:  0.8330729166666666 . Precision:  0.8238881493840875 . Recall:  1.0 . F1-Score:  0.9034415291993733\n"
     ]
    }
   ],
   "source": [
    "# NUM OF CLIENTS = TOTAL IMAGES / BATCH SIZE\n",
    "fl_iter = 10\n",
    "threshold = int(len(train_dataset1) / 10)\n",
    "train_loss_arr1 = []\n",
    "train_acc_arr1 = []\n",
    "train_prec_arr1 = []\n",
    "train_recall_arr1 = []\n",
    "train_f1_arr1 = []\n",
    "\n",
    "print(\"FL_ITER: \", fl_iter)\n",
    "print(\"NUM_CLIENTS_PER_FL_ITER: \", threshold)\n",
    "print(\"Batch Idx Size: \", len(client_loader1))\n",
    "\n",
    "\n",
    "for epoch in range(1, fl_iter + 1):\n",
    "  global_weights = get_global_weights_from_server()\n",
    "  local_gradients = []\n",
    "  net_loss = 0\n",
    "  net_i = 0\n",
    "  tn = 0\n",
    "  fp = 0\n",
    "  fn = 0\n",
    "  tp = 0\n",
    "  count=0\n",
    "  _accuracy=0\n",
    "  _precision=0\n",
    "  _recall=0\n",
    "  _f1=0\n",
    "\n",
    "  for fl_client in clients_arr:\n",
    "\n",
    "    copy_fl_client = copy.deepcopy(fl_client)\n",
    "    copy_fl_client.set_weights(copy.deepcopy(global_weights))\n",
    "    local_loss, _tn, _fp, _fn, _tp = copy_fl_client.train_model()\n",
    "    net_loss += local_loss\n",
    "    net_i += 1\n",
    "    tn += _tn\n",
    "    fp += _fp\n",
    "    fn += _fn\n",
    "    tp += _tp\n",
    "    _accuracy += (_tp+_tn)/(_tp+_fp+_tn+_fn)\n",
    "    _precision += _tp/(_tp+_fp)\n",
    "    _recall += _tp/(_tp+_fn)\n",
    "    _f1 += 2/((1/_recall) + (1/_precision))\n",
    "    count+=1\n",
    "    #local_gradients.append(fl_client.get_gradients())\n",
    "    print(\"--------Epoch \",epoch,\"Client \", net_i,\". Local Loss: \", local_loss, \". L-AC: \", _accuracy, \". L-P: \", _precision, \". L-R: \", _recall, \". L-F1: \", _f1)\n",
    "\n",
    "    if send_local_gradients_to_server(copy_fl_client.get_gradients()) is not True:\n",
    "            print(\"Error sending weights to server\")\n",
    "            break\n",
    "    del copy_fl_client\n",
    "\n",
    "\n",
    "\n",
    "  loss = net_loss / net_i\n",
    "  train_loss_arr1.append(loss)\n",
    "  #accuracy = (tp+tn)/(tp+fp+tn+fn)\n",
    "  #precision = tp/(tp+fp)\n",
    "  #recall = tp/(tp+fn)\n",
    "  #f1 = 2/((1/recall) + (1/precision))\n",
    "  accuracy=_accuracy/count\n",
    "  precision=_precision/count\n",
    "  recall=_recall/count\n",
    "  f1=2/((1/recall) + (1/precision))\n",
    "  train_acc_arr1.append(accuracy)\n",
    "  train_prec_arr1.append(precision)\n",
    "  train_recall_arr1.append(recall)\n",
    "  train_f1_arr1.append(f1)\n",
    "\n",
    "  print(\"Epoch \", epoch, \". Loss: \", loss, \". Accuracy: \", accuracy, \". Precision: \", precision, \". Recall: \", recall, \". F1-Score: \", f1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TEST SET"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_client_dataset = []\n",
    "for i in range(len(test_dataset)):\n",
    "    test_client_dataset.append((train_transforms(test_dataset[i][0]), torch.Tensor([1,0]) if test_dataset[i][1] == class_num_covid else torch.Tensor([0,1])))\n",
    "test_client_loader = torch.utils.data.DataLoader(dataset=test_client_dataset, batch_size=32)\n",
    "len(test_client_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "test_clients_arr = []\n",
    "for batch_idx, (test_features, test_labels) in enumerate(test_client_loader):\n",
    "  test_clients_arr.append(FL_Client(test_features, test_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  0 . Loss:  0.2877863049507141 . Accuracy:  0.9375 . Precision:  0.9230769230769231 . Recall:  1.0 . F1-Score:  0.9600000000000002\n",
      "Batch  1 . Loss:  0.2274615317583084 . Accuracy:  1.875 . Precision:  1.8461538461538463 . Recall:  2.0 . F1-Score:  1.9200000000000004\n",
      "Batch  2 . Loss:  0.2729840874671936 . Accuracy:  2.84375 . Precision:  2.809116809116809 . Recall:  3.0 . F1-Score:  2.901422265816577\n",
      "Batch  3 . Loss:  0.2654171884059906 . Accuracy:  3.810416666666667 . Precision:  3.769116809116809 . Recall:  4.0 . F1-Score:  3.8811277026432367\n"
     ]
    }
   ],
   "source": [
    "test_loss_arr = []\n",
    "test_acc_arr = []\n",
    "test_prec_arr = []\n",
    "test_recall_arr = []\n",
    "test_f1_arr = []\n",
    "\n",
    "_accuracy=0\n",
    "_precision=0\n",
    "_recall=0\n",
    "_f1=0\n",
    "global_weights = get_global_weights_from_server()\n",
    "\n",
    "for batch_idx, (test_features, test_labels) in enumerate(test_client_loader):\n",
    "\n",
    "    test_fl_client = FL_Client(test_features, test_labels)\n",
    "    test_fl_client.set_weights(copy.deepcopy(global_weights))\n",
    "    test_clients_arr.append(test_fl_client)\n",
    "    local_loss, _tn, _fp, _fn, _tp = test_fl_client.train_test_model_and_get_loss(test_features,test_labels)\n",
    "    _accuracy += (_tp+_tn)/(_tp+_fp+_tn+_fn)\n",
    "    _precision += _tp/(_tp+_fp)\n",
    "    _recall += _tp/(_tp+_fn)\n",
    "    _f1 = 2/((1/_recall) + (1/_precision))\n",
    "    test_loss_arr.append(local_loss)\n",
    "    test_acc_arr.append(_accuracy)\n",
    "    test_prec_arr.append(_precision)\n",
    "    test_recall_arr.append(_recall)\n",
    "    test_f1_arr.append(_f1)\n",
    "\n",
    "    print(\"Batch \", batch_idx, \". Loss: \", local_loss, \". Accuracy: \", _accuracy, \". Precision: \", _precision, \". Recall: \", _recall, \". F1-Score: \", _f1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  3 . Loss:  0.2634122781455517 . Accuracy:  0.9526041666666667 . Precision:  0.9422792022792023 . Recall:  1.0 . F1-Score:  0.9702819256608092\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loss = np.sum(test_loss_arr)/ len(test_loss_arr)\n",
    "test_accuracy = _accuracy/ len(test_acc_arr)\n",
    "test_precision = _precision/ len(test_prec_arr)\n",
    "test_recall= _recall/len(test_recall_arr)\n",
    "test_f1= _f1/ len(test_f1_arr)\n",
    "\n",
    "\n",
    "print(\"Batch \", batch_idx, \". Loss: \", test_loss, \". Accuracy: \", test_accuracy, \". Precision: \", test_precision, \". Recall: \", test_recall, \". F1-Score: \", test_f1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m8\u001B[39m,\u001B[38;5;241m5\u001B[39m))\n\u001B[0;32m      2\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(train_loss_arr1)),train_loss_arr1,color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdodgerblue\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mtitle(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mModel Convergence \u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(len(train_loss_arr1)),train_loss_arr1,color='dodgerblue')\n",
    "plt.title('Model Convergence ')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(len(train_acc_arr1)),train_acc_arr1,color='dodgerblue')\n",
    "plt.title('Accuracy Convergence')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(len(train_prec_arr1)),train_prec_arr1,color='dodgerblue')\n",
    "plt.title('Precision Convergence')\n",
    "plt.ylabel('precision')\n",
    "plt.xlabel('epochs')\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(len(train_recall_arr1)),train_recall_arr1,color='dodgerblue')\n",
    "plt.title('Recall Convergence')\n",
    "plt.ylabel('recall')\n",
    "plt.xlabel('epochs')\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(len(train_f1_arr1)),train_f1_arr1,color='dodgerblue')\n",
    "plt.title('F1 Convergence ')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Final_FL_Dark_Covid_Net.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}